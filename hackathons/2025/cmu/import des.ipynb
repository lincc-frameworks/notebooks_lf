{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6842fbb0-d241-45f9-93cf-4c58f02c1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q -r requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72560161-ed62-4df5-9813-ab21730f7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/ocean/projects/phy210048p/shared/hats/raw/DESY3_metacal_v03-004.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7bdb015-2993-4a0c-8856-3ce79757f2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hats\n",
    "hats.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "815ef432-f594-40cc-a4a2-5a2645bcd43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hats_import.catalog.file_readers import InputReader\n",
    "import pyarrow as pa\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "class ShapeCatalogReader(InputReader):\n",
    "    def __init__(self):\n",
    "        self.chunksize=100_00\n",
    "    def read(self, input_file, read_columns=None):\n",
    "        fh = h5py.File(input_file,'r')\n",
    "        dataset_len = fh['catalog']['unsheared']['ra'].len()\n",
    "        col_names = []\n",
    "        chunk_start = 0\n",
    "        chunk_end = self.chunksize\n",
    "        if read_columns is None:\n",
    "            tab_names = [f\"{key}\" for key in fh['catalog']['unsheared'].keys()]\n",
    "            col_names.extend(tab_names)\n",
    "            for table in ['sheared_1m', 'sheared_1p', 'sheared_2m', 'sheared_2p']:\n",
    "                tab_names = [f\"{table}_{key}\" for key in fh['catalog'][table].keys()]\n",
    "                col_names.extend(tab_names)\n",
    "        else:\n",
    "            ras = fh['catalog']['unsheared']['ra'][chunk_start:chunk_end]\n",
    "            ras = np.asanyarray(ras, dtype=ras.dtype.newbyteorder(\"=\"))\n",
    "            decs = fh['catalog']['unsheared']['dec'][chunk_start:chunk_end]\n",
    "            decs = np.asanyarray(decs, dtype=decs.dtype.newbyteorder(\"=\"))\n",
    "            yield pa.Table.from_arrays([ras, decs], names=[\"ra\", \"dec\"])\n",
    "\n",
    "        while chunk_start < dataset_len:\n",
    "            if read_columns is None:\n",
    "                col_vals = []\n",
    "                tab_values = [fh['catalog']['unsheared'][key][chunk_start:chunk_end] for key in fh['catalog']['unsheared'].keys()]\n",
    "                tab_values = [np.asanyarray(arr, dtype=arr.dtype.newbyteorder(\"=\")) for arr in tab_values]\n",
    "    \n",
    "                col_vals.extend(tab_values)\n",
    "                for table in ['sheared_1m', 'sheared_1p', 'sheared_2m', 'sheared_2p']:\n",
    "                    tab_values = [fh['catalog'][table][key][chunk_start:chunk_end] for key in fh['catalog'][table].keys()]\n",
    "                    tab_values = [np.asanyarray(arr, dtype=arr.dtype.newbyteorder(\"=\")) for arr in tab_values]\n",
    "        \n",
    "                    col_vals.extend(tab_values)\n",
    "                yield pa.Table.from_arrays(col_vals, names=col_names)\n",
    "            else:\n",
    "                ras = fh['catalog']['unsheared']['ra'][chunk_start:chunk_end]\n",
    "                ras = np.asanyarray(ras, dtype=ras.dtype.newbyteorder(\"=\"))\n",
    "                decs = fh['catalog']['unsheared']['dec'][chunk_start:chunk_end]\n",
    "                decs = np.asanyarray(decs, dtype=decs.dtype.newbyteorder(\"=\"))\n",
    "                yield pa.Table.from_arrays([ras, decs], names=[\"ra\", \"dec\"])\n",
    "            \n",
    "            chunk_start += self.chunksize\n",
    "            chunk_end = min(chunk_end+self.chunksize, dataset_len)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7f48fb9-529f-490f-8f10-ab22083cf4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hats_import.catalog.arguments import ImportArguments\n",
    "\n",
    "args = ImportArguments(\n",
    "    sort_columns=\"coadd_object_id\",\n",
    "    ra_column=\"ra\",\n",
    "    dec_column=\"dec\",\n",
    "    input_file_list=[path],\n",
    "    file_reader=ShapeCatalogReader(),\n",
    "    output_artifact_name=\"DESY3_metacal\",\n",
    "    output_path=\"/ocean/projects/phy210048p/shared/hats/catalogs/des/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb20b4-9c23-48cb-8d05-bf649860c857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Planning  : 100%|██████████| 4/4 [00:00<00:00, 1668.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_path (/ocean/projects/phy210048p/shared/hats/catalogs/des/DESY3_metacal/intermediate) contains intermediate files; resuming prior progress.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Binning   : 100%|██████████| 2/2 [00:23<00:00, 11.62s/it]\n",
      "Splitting :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from hats_import import pipeline\n",
    "\n",
    "pipeline(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcba667-a38e-489b-a77d-3a27039798b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipscat_mmd11",
   "language": "python",
   "name": "hipscat_mmd11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
