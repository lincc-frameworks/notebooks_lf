{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdb\n",
    "from tape import Ensemble, ColumnMapper\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "dask.config.set({'temporary_directory': '/data/epyc/users/brantd/tmp'})\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(n_workers=10, threads_per_worker=1,\n",
    "                memory_limit=\"60G\", processes=True)\n",
    "\n",
    "client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a custom-sized subset of ZTF for TAPE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to ZTF AXS\n",
    "ztf_object_path = \"/astro/store/epyc3/data3/hipscat/catalogs/ztf_axs/ztf_dr14\"\n",
    "ztf_source_path = \"/astro/store/epyc3/data3/hipscat/catalogs/ztf_axs/ztf_source/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Subsample using LSDB\n",
    "\n",
    "object_cols = [\"ps1_objid\", \"ra\", \"dec\"]\n",
    "source_cols = [\"ps1_objid\", \"ra\", \"dec\", \"mjd\", \"mag\", \"magerr\", \"band\"]\n",
    "\n",
    "# Load into LSDB catalog objects\n",
    "ztf_object = lsdb.read_hipscat(ztf_object_path) # ZTF Object\n",
    "ztf_source = lsdb.read_hipscat(ztf_source_path, columns=source_cols) # ZTF Source\n",
    "\n",
    "# Box Search to filter down to a small subset\n",
    "ra = (340, 342)\n",
    "dec = (10, 12)\n",
    "ztf_object = ztf_object.box(ra=ra, dec=dec)\n",
    "ztf_source = ztf_source.box(ra=ra, dec=dec)\n",
    "\n",
    "# Join Source to Object to set proper object-level _hipscat_index\n",
    "joined_source = ztf_object.join(\n",
    "    ztf_source, left_on=\"ps1_objid\", right_on=\"ps1_objid\", suffixes=(\"_object\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into TAPE\n",
    "\n",
    "# ColumnMapper Establishes which table columns map to timeseries quantities\n",
    "colmap = ColumnMapper(\n",
    "        id_col='_hipscat_index',\n",
    "        time_col='mjd',\n",
    "        flux_col='mag',\n",
    "        err_col='magerr',\n",
    "        band_col='band',\n",
    "      )\n",
    "\n",
    "ens = Ensemble(client=client)\n",
    "\n",
    "ens.from_lsdb(joined_source, ztf_object, column_mapper=colmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ens.object.npartitions, ens.source.npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to parquet for easy loading\n",
    "import numpy as np\n",
    "ens.source.index=ens.source.index.astype(np.uint64) # need this until lsdb 0.1.3\n",
    "ens.save_ensemble(\".\", \"ztf_small_ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gaia Hack LSDB",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
