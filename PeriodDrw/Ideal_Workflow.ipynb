{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdb\n",
    "import tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ztf_catalog \n",
    "import agn_catalog \n",
    "import PanSTARRS_catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all the AGN in the catalog\n",
    "# let us start with ZTF, i.e., find all AGN in ZTF\n",
    "agn_ztf = lsdb.crossmatch(primary=agn_catalog, secondary=ztf_catalog, radius=2.0, agn_ra='ra', agn_dec='dec', ztf_ra='ra', ztf_dec='dec')\n",
    "# remove very short lightcurves\n",
    "# in either of the two bands (r or g)\n",
    "agn_ztf = agn_ztf[agn_ztf['ndet'] > 10]\n",
    "# remove very faint objects (either band?)\n",
    "agn_ztf = agn_ztf[agn_ztf['median_mag'] < 20]\n",
    "# remove very bright objects (either band?)\n",
    "agn_ztf = agn_ztf[agn_ztf['median_mag'] > 16]\n",
    "# find duplicates, i.e., same AGN in multiple ZTF fields\n",
    "# they have different ZTF ids, but the same ra, dec\n",
    "agn_ztf_duplicates = lsdb.find_duplicates(agn_ztf)\n",
    "# connect the lightcurves and renormalize(?)\n",
    "agn_ztf.collate_and_renormalize(agn_ztf_duplicates)\n",
    "# find objects that might have been wrongly crossmatched?\n",
    "# for instance single spurious source closer to the real AGN than the real AGN\n",
    "agn_ztf_wrong = lsdb.find_wrong(agn_ztf)\n",
    "agn_ztf = agn_ztf[~agn_ztf_wrong]\n",
    "# some futher quality checks?\n",
    "\n",
    "\n",
    "\n",
    "# do the same for PanSTARRS\n",
    "agn_PST = lsdb.crossmatch(primary=agn_catalog, secondary=PanSTARRS_catalog, radius=2.0, agn_ra='ra', agn_dec='dec', PST_ra='raMean', PST_dec='decMean')\n",
    "# ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scientific analysis functions\n",
    "def estimate_drw(lightcurve):\n",
    "    \"\"\"Estimate the (damped random walk) DRW parameters for a lightcurve.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lightcurve : lsdb.Lightcurve\n",
    "        The lightcurve to estimate the DRW parameters for.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    quality: float\n",
    "        The quality of the fit    \n",
    "    tau : float\n",
    "        The DRW timescale.\n",
    "    sigma : float\n",
    "        The DRW amplitude.\n",
    "    \"\"\"\n",
    "    \n",
    "def estimate_drw_and_periods(lightcurve):\n",
    "    \"\"\"Estimate the DRW parameters and periodic parameters for a lightcurve.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lightcurve : lsdb.Lightcurve\n",
    "        The lightcurve to estimate the DRW and periodic parameters for.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    quality: float\n",
    "        The quality of the fit  \n",
    "    tau : float\n",
    "        The DRW timescale.\n",
    "    sigma : float\n",
    "        The DRW amplitude.\n",
    "    tau_period : float\n",
    "        The period timescale.\n",
    "    sigma_period : float\n",
    "        The period amplitude.\n",
    "    \"\"\"\n",
    "    \n",
    "def create_many_simulations(drw_parameters):\n",
    "    \"\"\"Create many simulated lightcurves from a DRW model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    drw_parameters : tuple\n",
    "        The DRW parameters (tau, sigma).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lightcurves : list of lightcurves\n",
    "        The simulated lightcurves.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best fit drw parameters for all AGN\n",
    "drw_ztf = agn_ztf.apply(estimate_drw)\n",
    "# best fit drw + period parameters for all AGN\n",
    "drw_period_ztf = agn_ztf.apply(estimate_drw_and_periods)\n",
    "\n",
    "# which of these AGN are good periodic candidates?\n",
    "# we simulate many lightcurves from the best fit drw model\n",
    "# and see how many of them show similar imrpovement in the fit when adding periodic terms\n",
    "# we know that the simulated data is not periodic, so the improvement is due to chance\n",
    "# only those AGN that show a more significant improvement in the real data than simulations will be periodic candidates\n",
    "\n",
    "agn_ztf_simulations  = create_many_simulations(drw_ztf['drw_tau'], drw_ztf['drw_sigma'])\n",
    "drw_ztf_simulations = agn_ztf.apply(estimate_drw)\n",
    "\n",
    "# additional scientific analysis function\n",
    "def compare_sim_and_real(data_fit_results, sim_fit_results):\n",
    "    \"\"\"Compare the quality results of the real data and the simulations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_fit_results : \n",
    "        Fitting results for the real data.\n",
    "    sim_fit_results : \n",
    "        Fitting results for the simulations.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lc_score : \n",
    "        For each lightcurves, show its score.\n",
    "        Score is the number of simulations that have a better fit than the real data.\n",
    "    \"\"\"\n",
    "\n",
    "# score each real lightcurve, how many simulations have a better fit than the real data?\n",
    "# this gives us a score for each lightcurve, how likely it is that it is actually periodic\n",
    "lc_score = compare_sim_and_real(drw_period_ztf, drw_ztf_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_period_agn_catalog_from_ztf = import_catalog(\"catalog from other authors that did similar work on ZTF\")\n",
    "\n",
    "# plot the results, and compare with the results from the previous work\n",
    "plt.scatter('agn data')\n",
    "plt.scatter('added data that was not in the previous work', color='different color')\n",
    "plt.plot('our fit')\n",
    "plt.plot('previous fit')\n",
    "\n",
    "\n",
    "# do similar workflow for PanSTARRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join lightcurves from ZTF and PanSTARRS\n",
    "# input/guidance expected from Chirs Suberlak (UW) and Vincenzo Petrecca (Napoli) \n",
    "# two possible workflows\n",
    "\n",
    "# Workflow 1 is supposed to do the global color correction\n",
    "# Workflow 2 is supposed to do the local color correction (i.e., for each AGN separately); something like ubercal\n",
    "\n",
    "# Not sure which one is better, or if we should do both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow 1\n",
    "# more information: https://docs.google.com/document/d/1v8jIje_DlDSqCcTZs_b2Ysd49UbTFRpYuH_Cqw3ytuU/edit#heading=h.rmz8988nl0o4\n",
    "\n",
    "# in this cell, we get a transformation between ZTF and PanSTARRS magnitudes in a given band ('r' or 'g')\n",
    "\n",
    "def find_standard_stars(ztf, PanSTARRS):\n",
    "    \"\"\"Find non-variable stars in the ZTF and PanSTARRS catalogs.\n",
    "    \n",
    "        Parameters\n",
    "    ----------\n",
    "    ztf: \n",
    "        ZTF catalog\n",
    "    PanSTARRS: \n",
    "        PanSTARRS catalog\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    standard_stars : lsdb.catalog\n",
    "        The standard stars. More specifically, the non-variable stars in both catalogs.\n",
    "    \"\"\"\n",
    "    # find non-variable stars in ZTF\n",
    "    # broadly, these stars should have similar characteristics as for AGN\n",
    "    ztf_stars = ztf[ztf['ndet'] > 10]\n",
    "    ztf_stars = ztf_stars[ztf_stars['median_mag'] < 20]\n",
    "    ztf_stars = ztf_stars[ztf_stars['median_mag'] > 16]\n",
    "    # can be as simple as np.std\n",
    "    # more likely, we want to use a more sophisticated method\n",
    "    # e.g., light-curve features (Rust based libary by Kostya)\n",
    "    variability_estimate_ztf = estimate_variability(ztf_stars)\n",
    "    ztf_non_var_stars = ztf_stars[variability_estimate_ztf < non_variabile_threshold_ztf]\n",
    "    \n",
    "    # do the same for PanSTARRS to get non-variable stars in PanSTARRS\n",
    "    pST_non_var_stars = pST_stars[variability_estimate_pST < non_variabile_threshold_pST]\n",
    "    \n",
    "    # match the two catalogs to get the non-variable stars in both catalogs\n",
    "    non_var_stars = lsdb.crossmatch(primary=ztf_non_var, secondary=pST_non_var, radius=2.0, ztf_ra='ra', ztf_dec='dec', PST_ra='raMean', PST_dec='decMean')\n",
    "    \n",
    "    return non_var_stars\n",
    "\n",
    "non_var_stars = find_standard_stars(ztf, PanSTARRS)\n",
    "\n",
    "# look at the relation between the bands in the two catalogs\n",
    "plt.scatter(non_var_stars['PST_g']-non_var_stars['PST_i'], non_var_stars['PST_r']-non_var_stars['ZTF_r'])\n",
    "\n",
    "# get relation between ZTF and PanSTARRS magnitudes\n",
    "# limits_gi is the range of g-i colors for which we want to fit the relation, captures most AGN,\n",
    "# and the fit is more reliable in this range\n",
    "fit_to_get_syntethic_r  = fit_polynomial_function(non_var_stars, band_1='ztf_g', band_2='PST_g', degree=2, limits_gi=[0, 1.2])\n",
    "# same for g, to get synthetic_g\n",
    "\n",
    "\n",
    "# to evaluate the quality of the fit, we can plot the residuals\n",
    "plt.scatter(non_var_stars['PST_g']-non_var_stars['PST_i'], non_var_stars['PST_r']-fit_to_get_syntethic_r(non_var_stars['ZTF_r']))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, we apply this tranformation to the AGN lightcurves\n",
    "\n",
    "agn_combined = lsdb.comine(agn_PST, agn_ztf, on='id')\n",
    "r_synthetic = fit_to_get_syntethic_r(agn_combined['ZTF_r'])\n",
    "g_synthetic = fit_to_get_syntethic_r(agn_combined['ZTF_g'])\n",
    "r_synthetic_errror = np.sqrt((agn_combined['ZTF_r_err']**2+sythethic_fit_error_r**2))\n",
    "g_synthetic_errror = np.sqrt((agn_combined['ZTF_g_err']**2+sythethic_fit_error_g**2))\n",
    "agn_combined.add_column('synthetic_r', r_synthetic)\n",
    "agn_combined.add_column('synthetic_g', g_synthetic)\n",
    "agn_combined.add_column('r_synthetic_errror', r_synthetic_errror)\n",
    "agn_combined.add_column('g_synthetic_errror', g_synthetic_errror)\n",
    "\n",
    "# to evaluate the quality, do the same for stars that you try to match to AGN colors\n",
    "# the stars should not show any trend or jumps between PanSTARRS and ZTF magnitudes\n",
    "# for each AGN find the star that has similar magnitude (+-0.1 mag) and then minimum distance in color space \n",
    "stars_like_agn = find_similar_stars(non_var_stars, agn_combined, band_1='ZTF_r',  band_3='PST_r', band_4='ztf_g', band_5='PST_g')\n",
    "r_synthetic = fit_to_get_syntethic_r(agn_combined['ZTF_r'])\n",
    "g_synthetic = fit_to_get_syntethic_r(agn_combined['ZTF_g'])\n",
    "stars_like_agn.add_column('synthetic_r', r_synthetic)\n",
    "stars_like_agn.add_column('synthetic_g', g_synthetic)\n",
    "\n",
    "difference_stars_r = compute_mean_magnitude(stars_like_agn, band='synthetic_r') - compute_mean_magnitude(stars_like_agn, band='PST_r')\n",
    "difference_stars_g = compute_mean_magnitude(stars_like_agn, band='synthetic_g') - compute_mean_magnitude(stars_like_agn, band='PST_g')\n",
    "\n",
    "# assert that there is no trend in the difference between two surveys, for stars\n",
    "assert np.mean(difference_stars_r)<0.05 and np.std(difference_stars_r) < 0.1\n",
    "assert np.mean(difference_stars_g)<0.05 and np.std(difference_stars_g) < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow 2 \n",
    "# find stars around each AGN, find zeropoints that minimize the scatter of these stars\n",
    "\n",
    "def find_calibration_stars(ztf, PanSTARRS, agn_combined):\n",
    "    \"\"\"Find non-variable stars in the ZTF and PanSTARRS catalogs around each AGN\n",
    "       \n",
    "        Parameters\n",
    "    ----------\n",
    "    ztf: \n",
    "        ZTF catalog\n",
    "    PanSTARRS: \n",
    "        PanSTARRS catalog\n",
    "    agn_combined:\n",
    "        Combined AGN catalog\n",
    "           \n",
    "    Returns\n",
    "    -------\n",
    "    calibration_stars : lsdb.catalog\n",
    "        The calibration stars \n",
    "    \"\"\"\n",
    "    # this first part can be same/similar to the previous workflow\n",
    "    # find non-variable stars in ZTF\n",
    "    ztf_stars = ztf[ztf['ndet'] > 10]\n",
    "    ztf_stars = ztf_stars[ztf_stars['median_mag'] < 20]\n",
    "    ztf_stars = ztf_stars[ztf_stars['median_mag'] > 16]\n",
    "    # can be as simple as np.std\n",
    "    # more likely, we want to use a more sophisticated method\n",
    "    # e.g., light-curve features\n",
    "    variability_estimate_ztf = estimate_variability(ztf_stars)\n",
    "    ztf_non_var_stars = ztf_stars[variability_estimate_ztf < non_variabile_threshold_ztf]\n",
    "    \n",
    "    # do the same for PanSTARRS to get\n",
    "    pST_non_var_stars = pST_stars[variability_estimate_pST < non_variabile_threshold_pST]\n",
    "    \n",
    "    # ehm, lets not do it with a for loop in actuallity \n",
    "    calibration_stars_per_AGN = []\n",
    "    for each agn:    \n",
    "        all_ztf_non_var_stars_same_chip = ztf_non_var_stars[chip == same_chip_as_agn]\n",
    "        all_pST_non_var_stars_same_chip = pST_non_var_stars[chip == same_chip_as_agn]\n",
    "        # cut on distance to AGN, magnitude differece, color difference\n",
    "        # how exactly? - see more discussion below\n",
    "        non_var_stars_for_one_AGN = combine(all_ztf_non_var_stars_same_chip, all_pST_non_var_stars_same_chip)\n",
    "        calibration_stars_per_AGN.append(non_var_stars_for_one_AGN)\n",
    "    \n",
    "    return calibration_stars_per_AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each set of calibration_stars_per_AGN, find the custom zeropoints that minimize the scatter in the stars\n",
    "# e.g., if you have 50 stars and 100 observations, the goal is to find 100 values that minimizes the scatter\n",
    "# in 50 stars\n",
    "# this is a linear algebra problem, and can be solved with a matrix inversion\n",
    "# the most tricky part is to find the right set of calibration stars\n",
    "# some testing is needed to find the right cuts on distance to AGN, magnitude differece, color difference\n",
    "custom_zeropoints = find_custom_zeropoints(calibration_stars_per_AGN)\n",
    "\n",
    "# apply these custom zeropoints to the AGN lightcurves (per AGN)\n",
    "# there must be some testing loop to find the right cuts on distance to AGN, magnitude differece, color difference\n",
    "\n",
    "agn_combined['r_custom_zp'] = agn_combined['r'] + custom_zeropoints\n",
    "agn_combined['g_custom_zp'] = agn_combined['g'] + custom_zeropoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have combined the lightcurves from ZTF and PanSTARRS, we can do the same analysis as \n",
    "# for ZTF only/PanSTARRS only\n",
    "\n",
    "drw_combined = agn_combined.apply(estimate_drw)\n",
    "# best fit drw + period parameters for all AGN\n",
    "drw_period_combined = agn_combined.apply(estimate_drw_and_periods)\n",
    "agn_combined_simulations  = create_many_simulations(drw_combined['drw_tau'], drw_combined['drw_sigma'])\n",
    "drw_combined_simulations = agn_combined.apply(estimate_drw)\n",
    "\n",
    "lc_score_combined = compare_sim_and_real(drw_period_combined, drw_combined_simulations)\n",
    "\n",
    "# find the best candidates for periodicity, compare with the results from pure ZTF and pure PanSTARRS\n",
    "\n",
    "\n",
    "\n",
    "# output the results, with the best parameters for each AGN, and the score of the fit\n",
    "\n",
    "# LSST predictions?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
