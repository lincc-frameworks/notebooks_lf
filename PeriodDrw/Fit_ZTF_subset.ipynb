{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Neven Caplar \n",
    "Last updated: 2023-11-30\n",
    "\n",
    "Goals: \n",
    "Fit the data\n",
    "\n",
    "Each Section can/should run independently,\n",
    "only these initial imports should be shared among all sections\n",
    "\n",
    "Open questions:\n",
    "None at the moment\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# from scipy.spatial import KDTree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import JaxPeriodDrwFit\n",
    "\n",
    "\n",
    "from tape.ensemble import Ensemble\n",
    "from tape.utils import ColumnMapper\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "# many workers\n",
    "# dask.config.set(scheduler='threads') \n",
    "\n",
    "dask.config.set({\"temporary-directory\" :'/epyc/ssd/users/ncaplar/tmp'})\n",
    "\n",
    "# does not work\n",
    "# from multiprocessing.pool import ThreadPool\n",
    "# dask.config.set(pool=ThreadPool(20))\n",
    "\n",
    "# one worker\n",
    "# dask.config.set(scheduler='processes')  \n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers=8, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "# cluster.adapt(minimum=10, maximum=40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.get(\"temporary-directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ens = Ensemble(client = client)  # initialize an ensemble object\n",
    "ens.client_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.get(\"temporary-directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup base directory for saving output files\n",
    "username= \"ncaplar\"\n",
    "basedir = f\"/astro/users/{username}/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup base directory for saving output files\n",
    "username= \"ncaplar\"\n",
    "basedir = f\"/astro/users/{username}/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZTF - Loading original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - move to shuffling notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_path = \"/data3/epyc/data3/hipscat/catalogs/ztf_dr14_x_agns_source\"\n",
    "\n",
    "from pyarrow import parquet\n",
    "# parquet.read_schema(f\"{rel_path}/Norder=8/Dir=210000/Npix=217286.parquet\", memory_map=True)\n",
    "\n",
    "parquet.read_schema(\"/epyc/projects3/sean_hipscat/agns_x_ztf_source/Norder=8/Dir=210000/Npix=217286.parquet\", memory_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "colmap = ColumnMapper(id_col=\"_hipscat_index\",\n",
    "                      time_col=\"mjd_ztf_source\",\n",
    "                      flux_col=\"mag_ztf_source\",\n",
    "                      err_col=\"magerr_ztf_source\",\n",
    "                      band_col=\"band_ztf_source\")\n",
    "ens.from_parquet(source_file=\"/epyc/projects3/sean_hipscat/agns_x_ztf_source/Norder*/Dir*/Npix*.parquet\",\n",
    "                 #object_file=datapath+\"object/*.parquet\",\n",
    "                 column_mapper=colmap,\n",
    "                 partition_size=\"1000MB\")\n",
    "ens._source.reset_index().set_index(\"_hipscat_index\").to_parquet(\"/astro/store/epyc3/data3/hipscat/catalogs/ztf_dr14_x_agns_source_repar_big/\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZTF - Repartitioned dataset / partitioning and fitting and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - move the shuffling part to the shuffling notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "directory_path = '/astro/store/epyc3/data3/hipscat/catalogs/ztf_dr14_x_agns_source_repar_big/'\n",
    "file_pattern = 'part.25*.parquet'\n",
    "\n",
    "matching_files = glob.glob(f'{directory_path}{file_pattern}')\n",
    "\n",
    "for file_path in matching_files:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(250,254):\n",
    "    name = f\"/astro/store/epyc3/data3/hipscat/catalogs/ztf_dr14_x_agns_source_repar_big/part.{i}.parquet\"\n",
    "    names.append(name)\n",
    "    \n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap = ColumnMapper(id_col=\"_hipscat_index\",\n",
    "                      time_col=\"mjd_ztf_source\",\n",
    "                      flux_col=\"mag_ztf_source\",\n",
    "                      err_col=\"magerr_ztf_source\",\n",
    "                      band_col=\"band_ztf_source\")\n",
    "ens.from_parquet(source_file=names,\n",
    "                 #object_file=datapath+\"object/*.parquet\",\n",
    "                 column_mapper=colmap,\n",
    "                 sorted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_object = ens._object.compute()\n",
    "ens_source = ens._source.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in GB\n",
    "ens_source.memory_usage(deep=True).sum()/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ens_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_source['SDSS_NAME_dr16q_constant'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### investigating the sample and fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.check_lightcurve_cohesion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.query(\"band_ztf_source == 'g'\", table=\"source\").prune(50)\n",
    "ens._lazy_sync_tables(table=\"object\")\n",
    "ens.calc_nobs(temporary=False)\n",
    "\n",
    "data = ens.compute('object')['nobs_total'].values.astype(int)\n",
    "\n",
    "bin_edges = range(0, 321 + 21, 20) \n",
    "plt.hist(data, bins=bin_edges, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rows(partition):\n",
    "    return len(partition)\n",
    "\n",
    "# Let us try the same thing again\n",
    "n_sources_per_div = ens._source.map_partitions(count_rows, meta=int).compute()\n",
    "\n",
    "print(\"Number of rows in each partition:\", n_sources_per_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 minutes, 95.17 GB used\n",
    "JaxPeriodDrwFit_instance = JaxPeriodDrwFit.JaxPeriodDrwFit()\n",
    "res_tsp_drw = ens.batch(JaxPeriodDrwFit_instance.optimize_map_drw, 'mjd_ztf_source', \"mag_ztf_source\", \"magerr_ztf_source\",\n",
    "                compute=True, meta=None, n_init=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZTF - reshuffled and fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "directory_path = '/astro/store/epyc3/data3/hipscat/catalogs/ztf_dr14_x_agns_source_repar_big_shuffled_test/'\n",
    "file_pattern = 'part.*.parquet'\n",
    "\n",
    "matching_files = glob.glob(f'{directory_path}{file_pattern}')\n",
    "\n",
    "for file_path in matching_files:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = pd.read_parquet(matching_files[0])\n",
    "test_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(0,4):\n",
    "    name = f\"/astro/store/epyc3/data3/hipscat/catalogs/ztf_dr14_x_agns_source_repar_big_shuffled_test/part.{i}.parquet\"\n",
    "    names.append(name)\n",
    "    \n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap = ColumnMapper(id_col=\"count\",\n",
    "                      time_col=\"mjd_ztf_source\",\n",
    "                      flux_col=\"mag_ztf_source\",\n",
    "                      err_col=\"magerr_ztf_source\",\n",
    "                      band_col=\"band_ztf_source\")\n",
    "ens.from_parquet(source_file=names,\n",
    "                 #object_file=datapath+\"object/*.parquet\",\n",
    "                 column_mapper=colmap,\n",
    "                 sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens._object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_c_ix = ens._source._hipscat_index.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_count = np.sort(np.unique(ens_c_ix.values, return_counts=True))[1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom divisions in the middle\n",
    "n_count[np.array([len(n_count)/4, 2* len(n_count)/4, 3* len(n_count)/4]).astype(int)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens._source.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_divisions = (1.0, 54.0, 135.0, 207.0, 1012.0)\n",
    "ens._source = ens._source.repartition(divisions=custom_divisions)\n",
    "ens._source.divisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = np.unique(ens._source.get_partition(0).compute()['_hipscat_index'].values, return_counts=True)  \n",
    "c3 = np.unique(ens._source.get_partition(3).compute()['_hipscat_index'].values, return_counts=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = range(0, 721 + 21, 20) \n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121 )\n",
    "plt.hist(c1[1], bins=bin_edges, edgecolor='k')\n",
    "plt.ylim(0, 5000)\n",
    "\n",
    "plt.subplot(122 )\n",
    "plt.hist(c3[1], bins=bin_edges, edgecolor='k')\n",
    "plt.ylim(0, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.5 minutes, 22.84 GB used without repartitioning\n",
    "\n",
    "JaxPeriodDrwFit_instance = JaxPeriodDrwFit.JaxPeriodDrwFit()\n",
    "res_tsp_drw = ens.batch(JaxPeriodDrwFit_instance.optimize_map_drw, 'mjd_ztf_source', \"mag_ztf_source\", \"magerr_ztf_source\",\n",
    "                compute=True, meta=None, n_init=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tape_static",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
